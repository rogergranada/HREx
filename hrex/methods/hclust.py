#!/usr/bin/python
#-*- coding: utf-8 -*-

"""
A bottom-up approach begins with every term in a distinct (singleton) cluster, 
and successively merges clusters together until a stopping criterion is satisfied 
or until all terms belong to one cluster. In details, hierarchical clustering 
performs the following steps:

1. create a node to each term;
2. compute the similarity between each pair of nodes using some similarity measure;
3. find the two most similar nouns and combine them by giving a common parent;
4. compute the similarity between the new node and all other nodes;

This module uses `fastcluster` [1] in order to group terms together.

[1] Daniel Müllner, fastcluster: Fast Hierarchical, Agglomerative Clustering Routines 
for R and Python, Journal of Statistical Software 53 (2013), no. 9, 1–18, 
URL http://www.jstatsoft.org/v53/i09/

@author: granada
""" 

import os
import sys
sys.path.insert(0, '..') # This line is inserted to find the package utils.arguments

import logging
logger = logging.getLogger('methods.slqs')
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)

# Set standard output encoding to UTF-8.
from codecs import getwriter, open
sys.stdout = getwriter('UTF-8')(sys.stdout)

from scipy import spatial
import numpy as np
try:
    import fastcluster
except ImportError as error:
    logger.error('You do not have module Fastcluster installed. Please download it at: http://danifold.net/fastcluster.html')
    sys.exit(1)
    
from structure.methods import AbstractMethod
from structure import dictionaries
 
class HClust(AbstractMethod):
    """
    Identify hierarchical relations using hierarchical clustering.
    """
    def __init__(self, dwords=None, dctxs=None, drels=None, Z=None):
        """
        Initiates the class HClust

        Parameters:
        -----------
        dwords : DicWords
            Dictionary of words in the form:
                word: (id, df)
        dctxs : DicWords
            Dictionary of contexts in the form:
                ctx: (id, df)
        drels : DicRels
            Dictionary of relations in the form:
                (idw, idc): weight
            where `weight` is a LMI - MinMax scored
        Z : numpy.ndarray
            Z matrix generated by fastcluster

        Notes:
        ------
        AbstractMethod sets default values and contains the precision, 
        recall and f-measure

        self.rels : list
            A list containing the Hypernym-hyponym relations found by the method. 
            The list has the form:
                [(idH_1, idh_1), (idH_2, idh_2), ...]

        self.gsrels : list
            A list containing the relations found in a gold standard.
        """
        default = {'window': 5, 'lex_mode':'lemma', 'cwords':True, 'ctw':'n', 'normalize':True, 'lower':True}
        AbstractMethod.__init__(self, default=default)
        self.dwords = dwords
        self.dctxs = dctxs
        self.drels = drels
        self.rels = []
        self.gsrels = []
        self.Z = Z


    def _coocurrenceMatrix(self):
        """
        Generate the cooccurrence matrix from `self.drels`. 
        The coocurrence matrix has the form:
                | idc1 | idc2 | idc2 | ... | idcm |
                |--------------------|-----|------| 
           idw1 |   0  |  20  |  43  | ... |  22  |
           idw2 |  23  |   0  |  38  | ... |  46  |
            ... | ...  | ...  | ...  | ... |   0  |
           idwn |   0  |  35  |  19  | ... |  31  |
                |--------------------|------------|
          
        Returns:
        --------
        dwcl : dictionary.DicWords
            Dictionary of words containing the new ids
        dccl : dictionary.DicWords
            Dictionary of contexts containing the new ids
        cmat : numpy.ndarray
            coocurrence matrix matrix containing relations between 
            words and contexts
        """
        size_w = len(self.dwords)
        size_c = len(self.dctxs)
        logger.info('creating matrix of (%d, %d)' % (size_w, size_c))
        cmat = np.zeros((size_w, size_c))
        for idw, idc in self.drels:
            tf = self.drels[(idw, idc)]
            cmat[idw][idc] = tf
        del self.drels
        return cmat


    def identifyRelations(self, Hhrels, mode='complete'):
        """
        Identify relations between terms based on the model. This function 
        uses self.dwords, self.dctx and self.drels in order to find the most 
        hierarchical related terms.

        Parameters:
        -----------
        Hhrels : array_like
            List containing tuples with the hypernym (H) and the hyponym (h) of a
            relation. For instance, the relations `car is-a automobile` was identified
            by another method and passed in Hrels as:
            Hrels = [('automobile', 'car')] 
        mode : string (optional) {single, complete, average, weighted, 
                                  ward, centroid, median}
            Mode in which terms are clustered together. The parameter is specified
            by fastcluster. For more information, please see:
            [fastcluster](http://danifold.net/fastcluster.html?section=3)

        Notes:
        ------
        In this method, the dictionary `drels` contains the pointwise mutual 
        information `pmi` instead of the term frequency `tf` associated to the 
        term and context. The relations found by the method are saved into 
        self.rels.
        """
        logger.info('creating the coocurrence matrix')
        cmat = self._coocurrenceMatrix()
        # create a distance matrix (calculate the distance between each pair of observations).
        logger.info('calculating the distance matrix')
        distance = spatial.distance.pdist(cmat)
        logger.info('generating Z matrix with method=%s' % mode)
        self.Z = fastcluster.linkage(distance, method=mode, preserve_input=False)
        del cmat, distance


        a='''
        keys = self.dwords.keys()
        for i in xrange(len(keys)):
            w1 = keys[i]
            idw1, e1 = self.dwords[w1]
            for j in xrange(i+1, len(keys)):
                w2 = keys[j]
                idw2, e2 = self.dwords[w2]

                if e1 and e2:
                    slqs = 1 - (float(e1)/e2)

                    if slqs > 0:
                        self.rels.append((w2, w1))
                    elif slqs < 0:
                        self.rels.append((w1, w2))
        '''


        def saveClusters(self, fname):
        """
        Save the Z matrix into a text file. 

        Parameters:
        -----------
        fname : string
            Path to the output file

        Notes:
        ------
        The output file has the format:
            id_1 id_2 sim el
        where the sequence `id_1` and `id_2` are the nodes ID, `sim` the 
        similarity between nodes, and `el` the number of elements in the cluster.
        E.g.
            1 2 0.211399 2
            3 6 0.235342 3
            4 5 0.329393 2
            7 8 0.555555 5
        """
        logger.info('saving Z matrix into %s' % fname)
        with open(fname, 'w', 'utf-8') as fout:
            for n1, n2, sim, nbcl in self.Z:
                fout.write('%d %d %f %d\n' % (n1, n2, sim, nbcl))


        def loadClusters(self, Zfile):
        """
        Load the matrix generated by ``fastcluster`` (Z matrix).

        Parameters:
        -----------
        Zfile : string
            Path to the file containing the Z matrix

        Notes:
        ------
        The content of Zfile is stored in `self.Z`.
        The file has the format:
            id_1 id_2 sim el
        where the sequence `id_1` and `id_2` are the nodes ID, `sim` the 
        similarity between nodes, and `el` the number of elements in the cluster.
        E.g.
            1 2 0.211399 2
            3 6 0.235342 3
            4 5 0.329393 2
            7 8 0.555555 5
        """
        logger.info('loading Z matrix from %s' % fname)
        with open(Zfile, 'r', 'utf-8') as fin:
            self.Z = np.empty((0, 4))
            for n, line in enumerate(fin):
                id1, id2, sim, nbcl = line.strip().split()
                self.Z = np.vstack([Z, np.array([int(id1), int(id2), np.double(sim), int(nbcl)])])
#End of class HClust
